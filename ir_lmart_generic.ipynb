{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ir_lmart.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# Stronger baseline: Listwise L2R - LambdaMART\n",
    "# Hyperparameter optimziation HPonsteroids requires Python 3!\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# REMOVE!!\n",
    "from eval_utils import *\n",
    "\n",
    "# HPO\n",
    "from hpo_utils import *\n",
    "\n",
    "from ir_utils import *\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# HPO server and stuff\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import argparse\n",
    "\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "from hpbandster.optimizers import RandomSearch as RS\n",
    "from hpbandster.examples.commons import MyWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "#         print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        \n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Classes\n",
    "class L2Ranker:\n",
    "    def __init__(self, ranklib_location, params, normalization=[]):\n",
    "        self.ranklib_location = ranklib_location\n",
    "        # Works with Oracle JSE\n",
    "        # java version \"1.8.0_211\"\n",
    "        # Java(TM) SE Runtime Environment (build 1.8.0_211-b12)\n",
    "        # Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)\n",
    "        self.params = params\n",
    "        self.ranker_command = ['java', '-jar', ranklib_location + 'RankLib-2.12.jar']\n",
    "        self.normalization = normalization\n",
    "        self.save_model_file = ''\n",
    "        \n",
    "#     def build(self, ir_tool_params):\n",
    "    def train(self, train_data_file, save_model_file, hpo_config):\n",
    "        self.save_model_file = save_model_file\n",
    "        self.log_file = save_model_file + '.log'\n",
    "        self.hpo_config= hpo_config\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-train',\n",
    "                                train_data_file,\n",
    "                                *self.normalization,\n",
    "                                *self.params,\n",
    "                                '-leaf', \n",
    "                                str(self.hpo_config['n_leaves']),\n",
    "                                '-shrinkage',\n",
    "                                str(self.hpo_config['learning_rate']),\n",
    "                                '-tree', # Oner regression tree per boosted iteration\n",
    "                                str(self.hpo_config['n_trees']),\n",
    "                                '-save',\n",
    "                                self.save_model_file   \n",
    "                            ] \n",
    "        \n",
    "        print(toolkit_parameters)\n",
    "        with open(self.log_file, 'wt') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.PIPE, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "\n",
    "        if err == b'':\n",
    "            print('Model saved: ', self.save_model_file)\n",
    "        else:\n",
    "#             print('error:', err, type(err))\n",
    "            print('Something went wrong on training, see log: ', self.log_file)\n",
    "            \n",
    "  \n",
    "\n",
    "    def gen_run_file(self, test_data_file, run_file):\n",
    "        pre_run_file = run_file.replace('run_', 'pre_run_', 1)\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-load',\n",
    "                                self.save_model_file,\n",
    "                                *self.normalization,\n",
    "                                '-rank',\n",
    "                                test_data_file,\n",
    "                                '-indri',\n",
    "                                pre_run_file     \n",
    "                            ] \n",
    "        \n",
    "#         print(toolkit_parameters)\n",
    "        with open(self.log_file, 'at') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.STDOUT, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "        print(err)\n",
    "    \n",
    "        print(run_file)\n",
    "        print(pre_run_file)\n",
    "        \n",
    "        generate_run_file(pre_run_file, run_file)\n",
    "        \n",
    "#         print('Run model saved: ', run_file)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# try:\n",
    "#     import keras\n",
    "#     from keras.datasets import mnist\n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Dense, Dropout, Flatten\n",
    "#     from keras.layers import Conv2D, MaxPooling2D\n",
    "#     from keras import backend as K\n",
    "# except:\n",
    "#     raise ImportError(\"For this example you need to install keras.\")\n",
    "\n",
    "# try:\n",
    "#     import torchvision\n",
    "#     import torchvision.transforms as transforms\n",
    "# except:\n",
    "#     raise ImportError(\"For this example you need to install pytorch-vision.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fakeParser:\n",
    "    def __init__(self):\n",
    "        self.min_budget = 2 \n",
    "        self.max_budget = 4\n",
    "        self.n_iterations = 4 \n",
    "        self.n_workers =4\n",
    "        self.dataset = 'bioasq' \n",
    "        self.data_split = 'test'\n",
    "#         self.data_split = 'train'\n",
    "#         self.data_split = 'dev'\n",
    "#         self.build_index = True\n",
    "        self.build_index = None\n",
    "        self.fold = '1'\n",
    "        self.gen_features = True\n",
    "#         self.gen_features = None\n",
    "        \n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Example 1 - sequential and local execution.')\n",
    "    parser.add_argument('--min_budget',   type=float, help='Minimum budget used during the optimization.',    default=2)\n",
    "    parser.add_argument('--max_budget',   type=float, help='Maximum budget used during the optimization.',    default=4)\n",
    "    parser.add_argument('--n_iterations', type=int,   help='Number of iterations performed by the optimizer', default=500)\n",
    "    parser.add_argument('--n_workers', type=int,   help='Number of workers to run in parallel.', default=5)\n",
    "    \n",
    "    parser.add_argument('--dataset',   type=str, help='')\n",
    "    parser.add_argument('--data_split',   type=str, help='')\n",
    "    parser.add_argument('--pool_size',   type=int, help='')\n",
    "#     parser.add_argument('--build_index', action='store_true')\n",
    "    parser.add_argument('--fold', type=str,   help='')\n",
    "#     parser.add_argument('--gen_features', action='store_true')\n",
    "\n",
    "#     args=parser.parse_args()\n",
    "    args = fakeParser()\n",
    "    \n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "    workdir = './workdir/'\n",
    "    confdir = './tvqa_config/'\n",
    "    gen_features_dir = workdir + 'gen_features_dir/'\n",
    "    ranklib_location = '../ranklib/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_data_file = gen_features_dir + 'l2r_features_train'\n",
    "    val_data_file = gen_features_dir + 'l2r_features_dev'\n",
    "    test_data_file = gen_features_dir + 'l2r_features_test'\n",
    "    \n",
    "    qrels_val_file = workdir + 'gold_answer_qrels_dev'\n",
    "\n",
    "    l2r_model = 'lmart'\n",
    "\n",
    "    enabled_features_file = confdir + 'tvqa' + '_' + l2r_model + '_enabled_features' # dont'f change to fold_dir!\n",
    "\n",
    "#     print(enabled_features_file)\n",
    "    # Train L2R model: LambdaMART\n",
    "    # Parameters \n",
    "\n",
    "    n_leaves = '10'\n",
    "    learning_rate = '0.1'\n",
    "    n_trees = '1000'\n",
    "    hpo_params = {'n_leaves': n_leaves, 'learning_rate': learning_rate, 'n_trees': n_trees}\n",
    "\n",
    "\n",
    "\n",
    "    metric2t = 'P@1' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "\n",
    "    ranker_type = '6' # LambdaMART\n",
    "\n",
    "    # normalization: Feature Engineering?\n",
    "#     norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "\n",
    "    l2r_params = [\n",
    "        '-validate',\n",
    "        val_data_file,\n",
    "        '-ranker',\n",
    "        ranker_type,\n",
    "        '-metric2t',\n",
    "        metric2t,\n",
    "        '-feature',\n",
    "        enabled_features_file\n",
    "    ]\n",
    "\n",
    "    # Run train\n",
    "\n",
    "    lmart_model = L2Ranker(ranklib_location, l2r_params)\n",
    "#     lmart_model = L2Ranker(ranklib_location, l2r_params, norm_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "params_list = [\n",
    "    train_data_file,\n",
    "    val_data_file,\n",
    "    lmart_model,\n",
    "    qrels_val_file\n",
    "]\n",
    "\n",
    "def eval_hpo(params_list, hpo_params):\n",
    "    \n",
    "    train_data_file = params_list[0]\n",
    "    val_data_file = params_list[1]\n",
    "    lmart_model = params_list[2]\n",
    "    qrels_val_file = params_list[3]\n",
    "    \n",
    "    hpo_params_suffix = 'nl' + str(hpo_params['n_leaves']) + 'lr' + str(hpo_params['learning_rate']) + 'nt' + str(hpo_params['n_trees'])\n",
    "    \n",
    "    save_model_file = workdir + 'lmart_' + hpo_params_suffix + '_model' \n",
    "    \n",
    "    lmart_model.train(train_data_file, save_model_file, hpo_params)\n",
    "    run_file = workdir + 'run_' + '_lmart_' + hpo_params_suffix\n",
    "    \n",
    "#   lmart_model.gen_run_file(test_data_file, run_file)\n",
    "\n",
    "    lmart_model.gen_run_file(val_data_file, run_file)\n",
    "    \n",
    "#     print(qrels_val_file)\n",
    "#     print(run_file)\n",
    "    eval_results = 'Nothing by now r_r'\n",
    "#     eval_results.update(lmart_model.hpo_config)\n",
    "#     eval_results['lmart_model'] = lmart_model\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_dev_model(best_model_params_file, random_iterations = 5000):\n",
    "# #     random_search = 'yes'\n",
    "    \n",
    "#     if random_search == 'yes':\n",
    "#         ## Heavy random search\n",
    "#         brange = np.arange(0.1,1,0.05)\n",
    "#         krange = np.arange(0.1,4,0.1)\n",
    "#         N_range = np.arange(5,500,1) # num of docs\n",
    "#         M_range = np.arange(5,500,1) # num of terms\n",
    "#         lamb_range = np.arange(0,1,0.1) # weights of original query\n",
    "\n",
    "#         ## Light random search\n",
    "# #         brange = [0.2]\n",
    "# #         krange = [0.8]\n",
    "# #         N_range = np.arange(1,50,2)\n",
    "# #         M_range = np.arange(1,50,2)\n",
    "# #         lamb_range = np.arange(0,1,0.2)\n",
    "        \n",
    "#         h_param_ranges = [brange, krange, N_range, M_range, lamb_range]\n",
    "#         params = get_random_params(h_param_ranges, random_iterations)\n",
    "\n",
    "#     else:\n",
    "#         brange = [0.2]\n",
    "#         krange = [0.8]\n",
    "#         N_range = [11]\n",
    "#         M_range = [10]\n",
    "#         lamb_range = [0.5]\n",
    "       \n",
    "#         params = [[round(b,3), round(k,3), round(N,3), round(M,3), round(Lambda,3)] \n",
    "#                   for b in brange for k in krange for N in N_range for M in M_range for Lambda in lamb_range]\n",
    "   \n",
    "#     print('# Params: ', len(params)) \n",
    "#     pool_size = 20\n",
    "# #     print(len(params))\n",
    "#     pool = multiprocessing.Pool(processes=pool_size,\n",
    "#                                 initializer=start_process,\n",
    "#                                 )\n",
    "\n",
    "# #     pool_outputs = pool.map(bm25_computing, params)\n",
    "    \n",
    "\n",
    "#     pool_outputs = pool.map_async(bm25_computing, params)\n",
    "# #     pool_outputs.get()\n",
    "#     ###\n",
    "\n",
    "    \n",
    "#     ##\n",
    "    \n",
    "    \n",
    "#     pool.close() # no more tasks\n",
    "#     while (True):\n",
    "#         if (pool_outputs.ready()): break\n",
    "#         remaining = pool_outputs._number_left\n",
    "# #         remaining2 = remaining1\n",
    "# #         remaining1 = pool_outputs._number_left\n",
    "#         if remaining%10 == 0:\n",
    "#             print(\"Waiting for\", remaining, \"tasks to complete...\")\n",
    "#             time.sleep(2)\n",
    "        \n",
    "      \n",
    "#     pool.join()  # wrap up current tasks\n",
    "#     pool_outputs.get()\n",
    "#     params_file = './best_ir_model/' + dataset_name_ext + '_' + 'bm25_rm3_' + split + '_hparams.pickle'\n",
    "#     pickle.dump(pool_outputs.get(), open(params_file, \"wb\" ) )\n",
    "#     print('Total parameters: ' + str(len(pool_outputs.get())))\n",
    "#     best_model_params = max(pool_outputs.get(), key=lambda x: x[5])\n",
    "    \n",
    "#     best_model_dict = {\n",
    "#         'b': best_model_params[0],\n",
    "#         'k': best_model_params[1],\n",
    "#         'N': best_model_params[2],\n",
    "#         'M': best_model_params[3],\n",
    "#         'Lambda': best_model_params[4],\n",
    "#         'random_iterations': random_iterations,\n",
    "#         'map': best_model_params[5],\n",
    "#         'p_20': best_model_params[6],\n",
    "#         'ndcg_20': best_model_params[7]\n",
    "        \n",
    "#     }\n",
    "#     best_model_dict = {k:str(v) for k, v in best_model_dict.items()} # everything to string\n",
    "    \n",
    "#     with open(best_model_params_file, 'wt') as best_model_f:\n",
    "#         json.dump(best_model_dict, best_model_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_process():\n",
    "    print( 'Starting', multiprocessing.current_process().name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_multi_hpo(params_list, hpo_params_list, pool_size):\n",
    "   \n",
    "    eval_hpo_partial = partial(eval_hpo, params_list)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=pool_size,\n",
    "                                initializer=start_process,\n",
    "                                )\n",
    "\n",
    "    pool_outputs = pool.map_async(eval_hpo_partial, hpo_params_list)\n",
    "    pool.close() # no more tasks\n",
    "    pool.join()  # wrap up current tasks\n",
    "    print('Total parameters: ' + str(len(pool_outputs.get())))\n",
    "    return pool_outputs.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "hpo_method = 'rs'\n",
    "\n",
    "random_iterations = 20 # these are outside parameters\n",
    "\n",
    "nleaves_range = np.arange(1,51,1)\n",
    "lrate_range = np.arange(0.1,1,0.1)\n",
    "ntrees_range = np.arange(1,51,1)\n",
    "\n",
    "h_param_ranges = [nleaves_range, lrate_range, ntrees_range]\n",
    "\n",
    "if hpo_method == 'rs':\n",
    "    h_params = get_random_params(h_param_ranges, random_iterations)\n",
    "elif hpo_method == 'gs':\n",
    "    h_params = get_grid_search_params(h_param_ranges)\n",
    "\n",
    "hpo_params_list = [{'n_leaves': x[0], 'learning_rate': x[1], 'n_trees': x[2]} for x in h_params]\n",
    "\n",
    "print(len(hpo_params_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ForkPoolWorker-1\n",
      "Starting ForkPoolWorker-3\n",
      "Starting ForkPoolWorker-2\n",
      "Starting ForkPoolWorker-4\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '33', '-shrinkage', '0.9', '-tree', '10', '-save', './workdir/lmart_nl33lr0.9nt10_model']\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '47', '-shrinkage', '0.6', '-tree', '8', '-save', './workdir/lmart_nl47lr0.6nt8_model']\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '41', '-shrinkage', '0.9', '-tree', '45', '-save', './workdir/lmart_nl41lr0.9nt45_model']\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '16', '-shrinkage', '0.2', '-tree', '40', '-save', './workdir/lmart_nl16lr0.2nt40_model']\n",
      "Starting ForkPoolWorker-5\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '14', '-shrinkage', '0.4', '-tree', '12', '-save', './workdir/lmart_nl14lr0.4nt12_model']\n",
      "Model saved:  ./workdir/lmart_nl14lr0.4nt12_model\n",
      "Model saved:  ./workdir/lmart_nl47lr0.6nt8_model\n",
      "Model saved:  ./workdir/lmart_nl33lr0.9nt10_model\n",
      "Model saved:  ./workdir/lmart_nl16lr0.2nt40_model\n",
      "None\n",
      "./workdir/run__lmart_nl14lr0.4nt12\n",
      "./workdir/pre_run__lmart_nl14lr0.4nt12\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '19', '-shrinkage', '0.2', '-tree', '37', '-save', './workdir/lmart_nl19lr0.2nt37_model']\n",
      "None\n",
      "./workdir/run__lmart_nl33lr0.9nt10\n",
      "./workdir/pre_run__lmart_nl33lr0.9nt10\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '45', '-shrinkage', '0.2', '-tree', '12', '-save', './workdir/lmart_nl45lr0.2nt12_model']\n",
      "None\n",
      "./workdir/run__lmart_nl47lr0.6nt8\n",
      "./workdir/pre_run__lmart_nl47lr0.6nt8\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '49', '-shrinkage', '0.6', '-tree', '23', '-save', './workdir/lmart_nl49lr0.6nt23_model']\n",
      "Model saved:  ./workdir/lmart_nl41lr0.9nt45_model\n",
      "None\n",
      "./workdir/run__lmart_nl16lr0.2nt40\n",
      "./workdir/pre_run__lmart_nl16lr0.2nt40\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '14', '-shrinkage', '0.7', '-tree', '42', '-save', './workdir/lmart_nl14lr0.7nt42_model']\n",
      "None\n",
      "./workdir/run__lmart_nl41lr0.9nt45\n",
      "./workdir/pre_run__lmart_nl41lr0.9nt45\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '12', '-shrinkage', '0.4', '-tree', '42', '-save', './workdir/lmart_nl12lr0.4nt42_model']\n",
      "Model saved:  ./workdir/lmart_nl45lr0.2nt12_model\n",
      "Model saved:  ./workdir/lmart_nl19lr0.2nt37_model\n",
      "Model saved:  ./workdir/lmart_nl49lr0.6nt23_model\n",
      "None\n",
      "./workdir/run__lmart_nl45lr0.2nt12\n",
      "./workdir/pre_run__lmart_nl45lr0.2nt12\n",
      "Model saved:  ./workdir/lmart_nl14lr0.7nt42_model\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '21', '-shrinkage', '0.7', '-tree', '25', '-save', './workdir/lmart_nl21lr0.7nt25_model']\n",
      "None\n",
      "./workdir/run__lmart_nl19lr0.2nt37\n",
      "./workdir/pre_run__lmart_nl19lr0.2nt37\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '45', '-shrinkage', '0.6', '-tree', '46', '-save', './workdir/lmart_nl45lr0.6nt46_model']\n",
      "None\n",
      "./workdir/run__lmart_nl49lr0.6nt23\n",
      "./workdir/pre_run__lmart_nl49lr0.6nt23\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '39', '-shrinkage', '0.3', '-tree', '30', '-save', './workdir/lmart_nl39lr0.3nt30_model']\n",
      "Model saved:  ./workdir/lmart_nl12lr0.4nt42_model\n",
      "None\n",
      "./workdir/run__lmart_nl14lr0.7nt42\n",
      "./workdir/pre_run__lmart_nl14lr0.7nt42\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '32', '-shrinkage', '0.9', '-tree', '5', '-save', './workdir/lmart_nl32lr0.9nt5_model']\n",
      "None\n",
      "./workdir/run__lmart_nl12lr0.4nt42\n",
      "./workdir/pre_run__lmart_nl12lr0.4nt42\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '29', '-shrinkage', '0.3', '-tree', '36', '-save', './workdir/lmart_nl29lr0.3nt36_model']\n",
      "Model saved:  ./workdir/lmart_nl21lr0.7nt25_model\n",
      "Model saved:  ./workdir/lmart_nl32lr0.9nt5_model\n",
      "None\n",
      "./workdir/run__lmart_nl21lr0.7nt25\n",
      "./workdir/pre_run__lmart_nl21lr0.7nt25\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '29', '-shrinkage', '0.4', '-tree', '42', '-save', './workdir/lmart_nl29lr0.4nt42_model']\n",
      "None\n",
      "./workdir/run__lmart_nl32lr0.9nt5\n",
      "./workdir/pre_run__lmart_nl32lr0.9nt5\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '24', '-shrinkage', '0.2', '-tree', '9', '-save', './workdir/lmart_nl24lr0.2nt9_model']\n",
      "Model saved:  ./workdir/lmart_nl39lr0.3nt30_model\n",
      "Model saved:  ./workdir/lmart_nl29lr0.3nt36_model\n",
      "Model saved:  ./workdir/lmart_nl45lr0.6nt46_model\n",
      "None\n",
      "./workdir/run__lmart_nl39lr0.3nt30\n",
      "./workdir/pre_run__lmart_nl39lr0.3nt30\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '19', '-shrinkage', '0.8', '-tree', '25', '-save', './workdir/lmart_nl19lr0.8nt25_model']\n",
      "Model saved:  ./workdir/lmart_nl24lr0.2nt9_model\n",
      "None\n",
      "./workdir/run__lmart_nl29lr0.3nt36\n",
      "./workdir/pre_run__lmart_nl29lr0.3nt36\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '45', '-shrinkage', '0.2', '-tree', '29', '-save', './workdir/lmart_nl45lr0.2nt29_model']\n",
      "None\n",
      "./workdir/run__lmart_nl45lr0.6nt46\n",
      "./workdir/pre_run__lmart_nl45lr0.6nt46\n",
      "['java', '-jar', '../ranklib/RankLib-2.12.jar', '-train', './workdir/gen_features_dir/l2r_features_train', '-validate', './workdir/gen_features_dir/l2r_features_dev', '-ranker', '6', '-metric2t', 'P@1', '-feature', './tvqa_config/tvqa_lmart_enabled_features', '-leaf', '11', '-shrinkage', '0.1', '-tree', '7', '-save', './workdir/lmart_nl11lr0.1nt7_model']\n",
      "None\n",
      "./workdir/run__lmart_nl24lr0.2nt9\n",
      "./workdir/pre_run__lmart_nl24lr0.2nt9\n",
      "Model saved:  ./workdir/lmart_nl29lr0.4nt42_model\n",
      "Model saved:  ./workdir/lmart_nl19lr0.8nt25_model\n",
      "Model saved:  ./workdir/lmart_nl11lr0.1nt7_model\n",
      "None\n",
      "./workdir/run__lmart_nl29lr0.4nt42\n",
      "./workdir/pre_run__lmart_nl29lr0.4nt42\n",
      "None\n",
      "./workdir/run__lmart_nl19lr0.8nt25\n",
      "./workdir/pre_run__lmart_nl19lr0.8nt25\n",
      "None\n",
      "./workdir/run__lmart_nl11lr0.1nt7\n",
      "./workdir/pre_run__lmart_nl11lr0.1nt7\n",
      "Model saved:  ./workdir/lmart_nl45lr0.2nt29_model\n",
      "None\n",
      "./workdir/run__lmart_nl45lr0.2nt29\n",
      "./workdir/pre_run__lmart_nl45lr0.2nt29\n",
      "Total parameters: 20\n"
     ]
    }
   ],
   "source": [
    "# hpo_params_list = [hpo_params]\n",
    "pool_size = 5\n",
    "\n",
    "hpo_results = eval_multi_hpo(params_list, hpo_params_list, pool_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a80f824e8e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model_hpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpo_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random_iterations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_lmart_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lmart_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model_hpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a80f824e8e13>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model_hpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpo_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random_iterations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_lmart_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lmart_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model_hpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_model_hpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "best_model_hpo = max(hpo_results, key=lambda x: x['map'])\n",
    "best_model_hpo['random_iterations'] = random_iterations\n",
    "best_model_hpo['data_split'] = 'validation'\n",
    "best_lmart_model = best_model_hpo.pop('lmart_model')\n",
    "best_model_hpo = {k: str(v) for k, v in best_model_hpo.items()}\n",
    "\n",
    "hpo_results_file = workdir + '_' + fold + '_' + l2r_model + '_hpo_results.pickle'\n",
    "best_model_hpo_file = workdir  +  'best_' + dataset + '_' + fold + '_' + l2r_model + '_hparams.json'\n",
    "\n",
    "pickle.dump(hpo_results, open(hpo_results_file, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_test_file = workdir + '_' + 'test_' + fold + '_qrels'\n",
    "\n",
    "run_file = workdir + 'run_' + dataset + '_' + fold + '_test_lmart_best'\n",
    "\n",
    "best_lmart_model.gen_run_file(test_data_file, run_file)\n",
    "\n",
    "eval_results = eval(trec_eval_command, qrels_test_file, run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results['data_split'] = 'test'\n",
    "eval_results\n",
    "\n",
    "best_model_hpo['test'] = eval_results\n",
    "\n",
    "with open(best_model_hpo_file, 'wt') as best_model_f:\n",
    "    json.dump(best_model_hpo, best_model_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
