{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bz2\n",
    "import pandas as pd\n",
    "# import dbmanager  as dbmanager\n",
    "from os.path import join\n",
    "import json\n",
    "import time \n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# nltk.download('punkt') # for english sentences tokenization\n",
    "\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load non processed data\n",
    "# file = './data/tvqa_qa_release/tvqa_train.jsonl'\n",
    "# with open(file, 'r') as f:\n",
    "#     lines = []\n",
    "#     for l in f.readlines():\n",
    "#         loaded_l = json.loads(l.strip(\"\\n\"))\n",
    "#         lines.append(loaded_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/tvqa_train_processed.json'\n",
    "val_file = './data/tvqa_val_processed.json'\n",
    "with open(val_file, 'r') as f:\n",
    "    processed_data_val = json.load(f)\n",
    "\n",
    "with open(train_file, 'r') as f:\n",
    "    processed_data_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_prediction(data):\n",
    "    gold_answers = []\n",
    "    predicted_answers = []\n",
    "    print(len(data))\n",
    "    for item in data:\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        q = [item['q']]\n",
    "        answers = [item['a' + str(i)] for i in range(0,5)]\n",
    "    #     print(answers)\n",
    "        tfidf_q = tfidf_vectorizer.fit_transform(q)\n",
    "    #     print(tfidf_q)\n",
    "        tfidf_answers = tfidf_vectorizer.transform(answers)\n",
    "    #     print(tfidf_answers)\n",
    "        cosine_similarities = linear_kernel(tfidf_q, tfidf_answers).flatten()\n",
    "        related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "        gold_answers.append(item['answer_idx'])\n",
    "        predicted_answers.append(related_docs_indices[0])\n",
    "    return [predicted_answers, gold_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[predicted_answers, gold_answers] = qa_prediction(processed_data_val)\n",
    "preds = np.asarray(predicted_answers)\n",
    "targets = np.asarray(gold_answers)\n",
    "acc = sum(preds == targets) / float(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sa_prediction(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    gold_answers = []\n",
    "    predicted_answers = []\n",
    "    for item in data:\n",
    "    #     print(item['q'])\n",
    "        sub = [item['located_sub_text']]\n",
    "        answers = [item['a' + str(i)] for i in range(0,5)]\n",
    "    #     print(answers)\n",
    "        tfidf_sub = tfidf_vectorizer.fit_transform(sub)\n",
    "    #     print(tfidf_q)\n",
    "        tfidf_answers = tfidf_vectorizer.transform(answers)\n",
    "    #     print(tfidf_answers)\n",
    "        cosine_similarities = linear_kernel(tfidf_sub, tfidf_answers).flatten()\n",
    "        related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "        gold_answers.append(item['answer_idx'])\n",
    "        predicted_answers.append(related_docs_indices[0])\n",
    "    return [predicted_answers, gold_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4711204353241985"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[predicted_answers, gold_answers] = sa_prediction(processed_data_val)\n",
    "preds = np.asarray(predicted_answers)\n",
    "targets = np.asarray(gold_answers)\n",
    "acc = sum(preds == targets) / float(len(preds))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_model(val_data, train_data):\n",
    "    tfidf_vectorizer_q_train = TfidfVectorizer()\n",
    "    gold_answers = []\n",
    "    predicted_answers = []\n",
    "    questions_train = [ele['q'] for ele in train_data]\n",
    "    tfidf_q_train = tfidf_vectorizer_q_train.fit_transform(questions_train)\n",
    "#     print(tfidf_q_train)\n",
    "    j = 0\n",
    "    for item in val_data:\n",
    "        j += 1\n",
    "#         print(j)\n",
    "    #     print(item['q'])\n",
    "#         print('main: ', tfidf_q_train.shape)\n",
    "        try:\n",
    "            q = [item['q']]\n",
    "    #         q_train = [q for q in train_data['q']]\n",
    "    #         answers = [item['a' + str(i)] for i in range(0,5)]\n",
    "        #     print(answers)\n",
    "    #         print(q)\n",
    "            tfidf_q = tfidf_vectorizer_q_train.transform(q)\n",
    "        #     print(tfidf_q)\n",
    "\n",
    "        #     print(tfidf_answers)\n",
    "            cosine_similarities_q_train = linear_kernel(tfidf_q, tfidf_q_train).flatten()\n",
    "            related_docs_indices_q_train = cosine_similarities_q_train.argsort()[:-5:-1]\n",
    "            q_similar_idx = related_docs_indices_q_train[0]\n",
    "    #         print(q_similar)\n",
    "            gold_a_idx = train_data[q_similar_idx]['answer_idx']\n",
    "            gold_train_answer = [train_data[q_similar_idx]['a' + str(gold_a_idx)]]\n",
    "    #         print(gold_train_answer)\n",
    "\n",
    "            tfidf_vectorizer_val = TfidfVectorizer()\n",
    "    #         print(gold_train_answer)\n",
    "            tfidf_q_val = tfidf_vectorizer_val.fit_transform(gold_train_answer)\n",
    "    #         print('second: ', tfidf_q_val.shape)\n",
    "\n",
    "            answers = [item['a' + str(i)] for i in range(0,5)]\n",
    "            tfidf_answers = tfidf_vectorizer_val.transform(answers)\n",
    "            cosine_similarities = linear_kernel(tfidf_q_val, tfidf_answers).flatten()\n",
    "            related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "            gold_answers.append(item['answer_idx'])\n",
    "            predicted_answers.append(related_docs_indices[0])\n",
    "        \n",
    "        except: \n",
    "            print(train_data[q_similar_idx])\n",
    "        \n",
    "        if j%1000 == 0:\n",
    "            print('processed: ', j)\n",
    "#         gold_answers.append(item['answer_idx'])\n",
    "#         predicted_answers.append(related_docs_indices[0])\n",
    "    return [predicted_answers, gold_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[predicted_answers, gold_answers] = retrieval_model(processed_data_val, processed_data_train)\n",
    "preds = np.asarray(predicted_answers)\n",
    "targets = np.asarray(gold_answers)\n",
    "acc = sum(preds == targets) / float(len(preds))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_train[3000]['answer_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train = [ele['q'] for ele in processed_data_train]\n",
    "questions_val = [ele['q'] for ele in processed_data_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer()\n",
    "td_2 = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_q_train = td.fit_transform(questions_train)\n",
    "tfidf_q_val = td_2.fit_transform(questions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_q_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(td)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
